% !TEX root = main.tex

\EK{

Computer mathematics studies processing of mathematical knowledge with a computer. It explores questions of how to represent mathematical problems and their proofs in a computer, how to check correctness of proofs by a computer and even how to construct proofs automatically using a computer. The latter is the domain of automated theorem proving. It is one of the central and hardest areas of computer mathematics and artificial intelligence. Automated methods of proving theorems precede the existence of computers (see e.g. \cite{bundy1999survey,davis2001early,harrison2007short} for a historical survey).

In order to be represented in a computer, a mathematical problem must be expressed in a language of some formal logic. Among the logics used for this purpose are propositional, first-order and higher-order logic, intuitionistic logic, modal, temporal, many-values logic and others.

Algorithms of automated theorem proving are implemented in computer programs called theorem provers. A theorem prover takes a logical conjecture as input and tries to either construct its proof or demonstrate that the conjecture is invalid. Theorem provers can be classified by the logic they support. Propositional, first-order and higher-order logic are among the logics that received the most attention in automated theorem proving. Reasoning in propositional logic, i.e. solving the problem of propositional satisfiability (SAT), is implemented in \emph{SAT solvers}, such as Lingeling~\cite{Lingeling} and Minisat~\cite{Minisat}. Solving the problem of satisfiability modulo theory (SMT) is implemented in \emph{SMT solvers}, such as Z3~\cite{Z3} and CVC4~\cite{CVC4}. Reasoning is first-order logic is implemented in \emph{first-order theorem provers}, such as Vampire~\cite{Vampire13}, E~\cite{E13} and iProver~\cite{iProver}. Reasoning in higher-order logic is implemented in \emph{higher-order theorem provers}, such as Satallax~\cite{Satallax} and Leo-II~\cite{LeoII}.

Generally speaking, the more expressive a logic is, the harder it is to reason in it. For example, satisfiability of a propositional problem can always be established, albeit possibly at a high computational cost. Modern SAT solvers implement elaborate algorithms that guarantee good performance characteristics in the average case. In contrast, satisfiability or unsatisfiability of a first-order problem cannot be in general established by any algorithm. Implementors of first-order provers face the challenge of making the provers succeed on as many real world problems as possible.

Theorem provers are used for software and hardware verification, information management, combinatorial reasoning, and more. They are also the most powerful mean of proof automation in interactive proof assistants. In most applications, the theorem checked by a theorem prover is generated by an external software tool and not given by a human. %Many verification tools integrate theorem provers and supply them with machine-generated theorems.

This thesis contributes to the area of automated theorem proving by presenting an extension of first-order logic that is useful for applications and can be supported by first-order theorem provers. This chapter describes the background of the thesis and is structured as follows. Section~\ref{sect:intro:fol} gives an introduction to automated theorem proving in first-order logic. Sections \ref{sect:intro:analysis} and \ref{sect:intro:itp} describe two important applications of first-order provers, automation for program verification and interactive proof assistants. Section~\ref{sect:intro:problem} states the problem addressed in the thesis, and finally Section~\ref{sect:intro:contributions} summarises the contributions of the thesis.
}

\EK{The thesis describes implementation details and challenges in the Vampire theorem prover, however the described features and their implementation can be carried out in any other first-order prover.}

\section*{Automated Theorem Proving}
\addcontentsline{toc}{section}{Automated Theorem Proving}

\EK{
\paragraph{Undecidability of first-order logic}

The problem of establishing validity of a first-order problem automatically can be traced back to Hilbert. In 1928 he posed a question, traditionally referred to as \emph{Entscheidungsproblem}\iffalse(German for ``decision problem'')\fi, stated as follows. Is there an algorithm that takes as input a statement in first-order logic and terminates with ``Yes'' or ``No'' according to whether or not the statement is valid?

This question has been answered negatively in 1936 independently by Church~\cite{church1936unsolvable} and Turing~\cite{turing1936computable}. Their proofs rely on the famous G\"{o}del's incompleteness theorem\iffalse~\cite{godel1931formal} (for an English translation see e.g. \cite[pp. 4--38]{davis1965undecidable})\fi. G\"{o}del's result entails that the problem of provability in first-order logic is not decidable, but \emph{semi-decidable}. Informally, it means that if a logical sentence of the form ``$\varphi$ implies $\psi$'' is valid, that can be established by enumerating all finite derivations in the logical system. A derivation between $\varphi$ and $\psi$ will necessarily be found in that enumeration. On the other hand, if the sentence is invalid, there is no algorithm that could in general demonstrate that.
}

\EK{
The main aim of automated first-order theorem proving is to determine satisfiability of a set of formulas, and possibly provide a certificate of the result, either in the form of a derivation of a false formula, or some representation of a model satisfying the input formulas.
}

\EK{A well known and generally best performing family of first-order proving algorithms are those based on various extensions of the calculus of ordered resolution and superposition described in \cite{NieuwenhuisRubio:HandbookAR:paramodulation:2001}.
}

\EK{
\paragraph{Refutation}

The problem of validity of a problem in first-order logic is often formulated in terms of unsatisfiability. Validity of a formula is equivalent to unsatisfiability of its negation. To prove validity of a formula one can derive contradiction from its negation, thus constructing a proof by \emph{refutation}. Conversely, invalidity of a formula is equivalent to satisfiability of its negation. To demonstrate invalidity of a formula one can find a model of its negation. Algorithms that search for satisfiability and unsatisfiability of first-order formulas are usually implemented as separate procedures.

}

\EK{
\paragraph{Clausification}
This involves the replacement of existentially quantified variables by Skolem functions, the expansion of equivalences, rewriting to negation normal form and then application of associativity rules to reach conjunctive normal form. It is well know that this process can lead to an explosion in the number of clauses.

Methods of first-order reasoning usually work not with arbitrary first-order formulas, but with first-order clauses. A first-order formula is in clausal normal form (CNF) if it has the shape $\forall x_1\ldots\forall x_n(C_1\wedge\ldots\wedge C_n)$, where each of $C_1,\ldots,C_n$ is a disjunction of literals. An alternative representation of a CNF is a set of first-order clauses. A first-order clause is an implicitly universally quantified disjunction of positive and negative first-order literals. A CNF translation converts an arbitrary first-order formula to CNF, preserving satisfiability. First-order provers that support formulas in full first-order logic implement such translations as part of their preprocessing of the input.

}

\EK{
\paragraph{Saturation-based proof search, AVATAR}
After a clause set has been produced, Vampire attempts to saturate this set with respect to some inference system I. The clause set is saturated if for every inference from I with premises in S the conclusion of the inference is also added to S. If the saturated set S contains a contradiction then the initial formulas are unsatisfiable. Otherwise, if I is a complete inference system and, importantly, the requirements for this completeness have been preserved, then the initial formulas are satisfiable. Finite saturation may not be possible and many heuristics are employed to make finding a contradiction more likely.
To compute this saturation we use a set of active clauses, with the invariant that all infer- ences between active clauses have been performed, and a set of passive clauses waiting to be activated. The algorithm then iteratively selects a given clause from passive and performs all necessary inferences to add it to active. The results of these inferences are added to passive (after undergoing some processing). This is illustrated in Figure 1. An important aspect of this process is clause selection. Clauses are selected either based on their age (youngest first) or their weight (lightest first) with these two properties being alternated in some specified ratio.
A recent addition to this story is AVATAR [50, 40], which (optionally) performs clause splitting using a SAT solver. The main point here is that the success of AVATAR is driven by the observation that saturation-based proof search does not perform well with long or heavy clauses. Therefore, encodings should avoid the introduction of such clauses. As an additional point, AVATAR can only be utilised if the boolean structure of a problem is exposed at the literal-level. For example, including a predicate implies with associated axioms would not play to AVATAR's strengths.

Vampire's main algorithm is saturation of a set of first-order clauses using the resolution and superposition calculus.
}

\EK{
\paragraph{Resolution and Superposition}

Despite the complexity of automated reasoning in first-order logic, several methods were found to be efficient for finding unsatisfiability for non-trivial problems. Modern state-or-the-art automated theorem provers are based on superposition calculus~\cite{NieuwenhuisRubio:HandbookAR:paramodulation:2001} and its refinements. Finding satisfiability is a much harder problem because a formula might only have infinite models.\iffalse In practice, the search for satisfiability is limited to finite models.\fi

Superposition-based theorem proving stems from the work of Robinson~\cite{Robinson65} on \emph{resolution calculus}. Resolution calculus establishes unsatisfiability of a set of first-order clauses by systematically and exhaustively applying a set of inference rules which include the resolution inference rule. Resolution calculus is refutationally complete, meaning that a contradiction can be deduced from any unsatisfiable set of clauses. The novelty of Robinson's work was in the usage of \emph{unification} for instantiation of variables. Unification avoids combinatorial explosion of ground instances of quantified formulas that was present e.g. in an earlier algorithm of Davis and Putnam \cite{davis1960computing}\footnote{This algorithm however retained as the prevalent method for establishing propositional satisfiability after a refinement by Logemann and Loveland~\cite{davis1962machine}.}.

Resolution calculus is refined by \emph{superposition calculus}~\cite{BG90, BG94} that employs term orderings for restricting the number of inferences. The basic idea of superposition is to only allow inferences that replace ``big'' terms by ``smaller'' ones, with respect to the given ordering.

Vampire uses resolution and superposition as its inference system I [1, 34]. A key feature of this calculus is the use of literal selection and orderings to restrict the application of inference rules, thus restricting the growth of the clause sets. Vampire uses a Knuth-Bendix term ordering (KBO) [23, 25, 32] which orders terms first by weight and then by symbol precedence whilst agreeing with a multisubset ordering on free variables. The symbol ordering is taken as a parameter but is relatively coarse in Vampire e.g. by order of occurrence in the input, arity, frequency or the reverse of these. There has been some work beginning to explore more clever things to do here [22, 38] but we have not considered treating symbols introduced by translations differently (although they will appear last in occurrence).

Saturation-based theorem provers such as E~\cite{E13}, Spass~\cite{Spass} or Vampire~\cite{Vampire13} construct proofs of unsatisfiability of first-order problems. To that end, they first convert the input problem into a set of first-order clauses and then try to derive contradiction from it. Theorem provers saturate the search space by inferring new clauses with inference rules such as binary resolution~\cite{Ganzinger01} and superposition~\cite{NieuwenhuisRubio:HandbookAR:paramodulation:2001}. They employ multiple techniques to prune the search space such as simplification orderings, selection functions and redundancy elimination.
}

\EK{
\paragraph{Term Ordering}
An important ingredient in paramodulation is the use of \emph{term orderings} for restricting the number of inferences. The basic idea of ordered paramodulation is to only perform replacements of ``big'' terms by ``smaller'' ones, with respect to the given ordering. The first instances of ordered paramodulation appeared in Knuth-Bendix completion~\cite{KB83}. Roughly, a completion procedure attempts to transform a given set of equations into an equivalent confluent one. A crucial step of the transformation process is the computation of critical pairs between equations. A critical pair is an equation obtained by \emph{superposition}, the restricted version of paramodulation in which inferences only involve left hand sides of possible rewrite steps, i.e., only the ``big'' terms (w.r.t. the given ordering) are considered. During the completion process equations are simplified by rewriting, and tautologies are removed. \EK{I don't quite undestand this, so it reads a bit vague.} Bachmair and Ganzinger refined these ideas into what got to be known as \emph{superposition calculus}~\cite{BG90, BG94}, that now forms the basis for most first-order theorem provers.
}

\EK{
\paragraph{Redundancy} Another very important concept related to saturation is the notion of redundancy. The idea is that some clauses in S are redundant in the sense that they can be safely removed from S without compromising completeness. The notion of saturation then becomes saturation-up-to- redundancy [1, 34]. An important redundancy check is subsumption. A clause A subsumes B if some subclause of B is an instance of A, in which case B can be safely removed from the search space as doing so does not change the possible models of the search space S. The fact that Vampire removes redundant formulas is good but if there is a lot of redundancy in the encoding we can still have issues as this removal can be lazy (e.g. when using the discount saturation loop that does not remove redundancies from the passive set).
}

\EK{
\paragraph{AVATAR}
Vampire also implements the AVATAR architecture~\cite{DBLP:conf/cav/Voronkov14} for splitting clauses. The idea behind AVATAR is to use a SAT or an SMT solver to guide proof search. AVATAR selects sub-problems for the saturation-based prover to tackle by making decisions over a propositional abstraction of the clause search space. The \tt{-sas} option of Vampire selects the SAT solver.
}

%\paragraph{Portfolio of proof search strategies}
Proof search strategies for first-order logic can be configured in many ways, and different proof strategies might solve different problems. Theorem provers such as E, iProver and Vampire implement not just one proof search strategy, but a portfolio of them. Based on certain characteristics of the input, theorem provers select the appropriate proof search strategies and schedules for them, and then run these strategies one by one in a time-slicing fashion. This approach allows theorem provers to succeed on a larger number of problems. Some provers extend their portfolios with proof search techniques other than saturation. For example, Vampire includes in its portfolios an implementation of the Inst-Gen calculus~\cite{DBLP:conf/birthday/Korovin13} and a finite model builder~\cite{VampireFMB}.

First-order theorem provers are currently evaluated empirically. Comparison of provers is mostly based on success rates and run times on standard corpora of problems. The main corpus is the Thousands of Problems for Theorem Provers (TPTP) library~\cite{TPTP}. The problems in this corpus are written in a variety of languages, such as FOF for untyped first-order formulas, TFF0~\cite{tff0} for typed monomorphic first-order formulas and TFF1~\cite{tff1} for typed rank-1 polymorphic first-order formulas. The TPTP library is used as a basis for the annual CASC system competition~\cite{CASC}.

\section*{Applications}
\addcontentsline{toc}{section}{Applications}
\EK{TODO}

\subsection*{Deductive Program Verification}
\addcontentsline{toc}{subsection}{Deductive Program Verification}
\EK{
Methods of program verification check that a program satisfies its specification. A program specification can be expressed with logical formulas that annotate program statements, capturing their properties. Typical examples of such properties are pre- and post-conditions, loop invariants and Craig interpolants. These program properties are checked using various tools, including theorem provers (see e.g. \cite{Bonacina10} for a detailed overview).

Automated program verification sees compliance with specification as a theorem that can be automatically checked by theorem provers. For that, program statements are first translated to logical formulas that capture the semantics of the statements. Then, a theorem is built with the translated formulas as axioms and program properties as the conjecture. Validity of the theorem is interpreted as that the program statements have their annotated properties.

Theorem provers can be used not just for checking program properties, but also for generating them. Recent approaches in interpolation and loop invariant generation~\cite{McMillan08,fase2009,hoder2012popl} present initial results of using first-order theorem provers for generating quantified program properties. First-order theorem provers can also be used to generate program properties with quantifier alternations~\cite{fase2009}; such properties could not be generated fully automatically by any previously known method.
}

\subsection*{Automation for Proof Assistants}
\addcontentsline{toc}{subsection}{Automation for Proof Assistants}
\EK{
Proof assistants are software tools that assist users in constructing proofs of mathematical problems. Proof assistants use formalisations of mathematics based on higher-order logic (Isabelle/HOL~\cite{Isabelle}), type theory (Coq~\cite{Coq}), set theory (Mizar~\cite{Mizar}) and others.

Many proof assistants enhance the workflow of their users by automatically filling in parts of the user's proof with the help of tactics. Tactics are specialised scripts that run a predefined collection of proof searching strategies. These strategies can be implemented inside the proof assistant itself or rely on third-party automated theorem provers~\cite{Sledgehammer,DBLP:conf/icms/UrbanHV10}.

To automate proof search for a problem using a theorem prover, a proof assistant first translates the problem into the logic supported by the theorem prover. Since the logics of proof assistants are usually more expressive than the logics of automated provers, this translation can be incomplete. If the theorem prover reports back a proof, the proof assistant uses it to reconstruct a proof in its own logic.
}

\section*{Motivation}
\addcontentsline{toc}{section}{Motivation}
First-order theorem provers have proved themselfes effective in several practical applications, however, their efficient usage remains challenging. One of the challenges is representation of application problems in first-order logic in a way that is efficient for automated reasoning. Systems of deductive program verification and proof assistants that rely on first-order provers usually do not deal with first-order logic natively. Instead, they translate problems in their respective domains (program properties or formulas in the logic of the proof assistant) to problems in first-order logic. There could be multiple ways of translating a problem because of the mismatch between the semantics of the domain and that of first-order logic. A theorem prover might succeed on the results of some of these translations and fail on the others. Users of a theorem prover might find designing a translation that is friendly to the prover to be a difficult task.

Theorem provers, especially first-order ones, are known to be fragile with respect to the input. Multiple, often subtle, characteristics of a first-order problem might affect the performance of the saturation-based proof search. These characteristics include, for example, the number of clauses in the problem, the size of clauses and the size of the signature. The combination of the problem and the particular setup of the proof search, such as the used selection function and term ordering, might be crucial for the success of the prover. Encoding a problem in the ``right'' format might therefore require solid knowledge of how theorem provers work and are implemented~--- something that a user of a prover might not have.

Assessing whether a translation of a certain problem to first-order logic is good might be difficult as well. Such assessment can often only be made through tedious experiments with running theorem provers, configured with different settings, on the results of the translation. A perfect translation might not necessarily exist, because different translation might work better in different scenarios. Furthermore, for some types of problems, their translations to first-order logic cannot be efficiently handled by a theorem prover at all unless it is extended with specialized rules and heuristics.

The complexity of preparing problems for first-order theorem provers can be battled by extending the logic, supported by the provers. Such extension should include theories and new syntactical features that are common in applications but sensitive to translations. The appropriate translation of these features to plain first-order logic therefore becomes the responsibility of the provers themselves. The right choice of new features and their efficient implementation in theorem provers facilitates applications of automated theorem proving. Firstly, users of theorem provers are relieved from the tedious translations and can express their problems closer to their original domain. Secondly, theorem provers are able to implement a translation that suits them best. Thirdly, theorem provers that implement portfolios of proof search strategies are able to try multiple different translations in the same run of the prover. Finally, theorem provers are able to enhance proof search for problems with specific features by implementing dedicated inference rules and other techniques.

This thesis addresses the following research question: \emph{which extensions of first-order theorem provers are useful for applications and how can these extensions be efficiently implemented?} The thesis identifies the following syntactical constructs that are generally not supported by first-order provers: first class boolean sort, \ITE\ expressions and \LETIN\ expressions. These constructs are ubiquitous in problems coming from program verification and interactive theorem provers, but all of them currently require specialised translations. Boolean values in programming languages are used both as expressions in conditional or loop statements and as boolean flags passed as arguments to functions. A natural way of translating program statements with booleans into formulas is by translating conditions as formulas and function arguments as terms. Yet we cannot mix boolean terms and formulas in the same way in first-order logic, unless the boolean sort is first class. Properties expressed in higher-order logic routinely use quantification over the interpreted boolean sort; this is not allowed in first-order logic either. Both programming languages and logic of proof assistants actively use \ITE\ and \LETIN\ statements that require non-trivial dedicated translation in first-order logic.

%\EK{The problem addressed in this thesis is the extension of the input language and underlying logic of first-order theorem provers with these constructs.}

\section*{Contributions of the Thesis}
\label{sect:intro:contributions}
\addcontentsline{toc}{section}{Contributions of the Thesis}

%The thesis focuses on practical features extending first-order theorem provers for making them better suited for applications of program verification and proof automation for interactive theorem provers.

This thesis contributes to the area of automated reasoning by exploring which extensions of first-order theorem provers facilitate their practical applications. Firstly, the thesis presents an extension FOOL of first-order logic that contains the missing syntactical constructs mentioned before. Secondly, it explores how reasoning in FOOL can be implemented in existing automated theorem provers for first-order logic. Finally, it gives evidence of usefulness of FOOL and efficiency of reasoning with it for practical applications. The rest of this section summarizes the main contributions of the thesis.

\paragraph{FOOL}
The thesis presents FOOL, standing for first-order logic (FOL) with boolean sort. \folb{} extends ordinary many-sorted FOL with \begin{enumerate*}[label=(\roman*)]\item first class boolean sort, \item boolean variables used as formulas, \item formulas used as arguments to function and predicate symbols, \item \ITE\ expressions and \item \LETIN\ expressions.\end{enumerate*} \ITE\ and \LETIN\ expressions can occur as both terms and formulas. \LETIN\ expressions can use (multiple simultaneous) definitions of function symbols, predicate symbols, and tuples. The thesis presents the definition of FOOL, its semantics, and a simple model-preserving translation from \folb{} formulas to formulas of first-order logic. This translation can be used to support \folb{} in existing first-order provers.

\paragraph{Reasoning with FOOL}
The thesis presents two approaches to an implementation of FOOL in first-order provers that improve over the simple translation of FOOL to FOL. The first approach is a new technique of dealing with the boolean sort in superposition theorem provers. This teachnique includes replacement of one of the boolean sort axioms with a specialised inference rule, called FOOL paramodulation. The second approach is a new algorithm \nfcnf{} that transforms FOOL formulas directly to first-order clauses. The thesis presents an implementation of the simple translation from FOOL to FOL and both improved approaches in Vampire.

\paragraph{Applications of FOOL}
The thesis presents an encoding of the next state relations of imperative programs in FOOL. Compared to similar methods, this encoding avoids introducing intermediate variables and results in FOOL formulas that consicely represent program fragments in logic.
%The thesis presents a translation of imperative programs annotated with their pre- and post-conditions to partial correctness properties of these programs.
The thesis present a work on verification of virtual private cloud network configurations with Vampire. The encoding of verification problems in this work relies on first class booleans, the theory of arrays and the theory of tuples.

\paragraph{Practical Evaluation}
The thesis presents extensive experimens on running Vampire, other first-order theorem provers, higher-order theorem provers and SMT solvers on FOL and FOOL problems. These problems come from various sources: benchmarks from the TPTP and SMT-LIB library, proof obligations generated by the Isabelle proof assistant, and verification conditions generated by multiple different program verification tools. The experimental results obtained with these problems show in particular that \begin{enumerate}
  \item Vampire with FOOL paramodulation performs better than Vampire with the simple translation from FOOL to FOL;
  \item Vampire with \nfcnf{} performs better that Vampire with FOOL paramodulation;
  \item Vampire performs better on verification conditions translated to FOOL than translated to FOL using current state-of-the-art methods.
\end{enumerate}

\paragraph{Impact on TPTP}
The language of FOOL is a superset of TFF0~--- the monomorphic first-order part of the TPTP language. The thesis describes a modification of the TPTP language needed to represent \folb{} formulas. This modification has been included in the TPTP standard as the TPTP Extended Typed First-Order Form (TFX).

\paragraph{Impact on Vampire}
The language of FOOL is a superset of the core theory of the SMT-LIB language~\cite{SMT-LIB}, the standard language of SMT solvers. First-order provers that support \folb{} can therefore reason about some problems from the SMT-LIB library. This opens up an opportunity to evaluate first-order provers on problems that were previously only checked by SMT solvers. Vampire gained support for SMT-LIB based on its implementation of FOOL, and since 2016 has been participating in the SMT-COMP competition~\cite{DBLP:conf/cav/BarrettMS05} where it contends against SMT solvers.

\section*{Structure of the Thesis}
\label{sect:intro:overview}
\addcontentsline{toc}{section}{Structure of the Thesis}

The work described in this thesis has been carried out in six papers, each contained in a separate chapter. Four papers (Chapters~\ref{chap:fool}, \ref{chap:implementation}, \ref{chap:cnf} and \ref{chap:boogie}) were published in peer-reviewed conferences, one (Chapter~\ref{chap:tfx}) was published in a peer-reviewed workshop, and one (Chapter~\ref{chap:aws}) is a technical report not yet submitted for publication. The references of the papers have been combined into a single bibliography at the end of the thesis. Other than that, the papers have only been edited for formatting purposes, and in general appear in their original form.

The chapters of this thesis are placed in the order in which their correspondent papers were written. Chapter~\ref{chap:fool} presents the syntax and semantics of FOOL. Chapter~\ref{chap:implementation} presents the implementation of FOOL in Vampire. Chapter~\ref{chap:cnf} presents an efficient clausification algorithm for FOOL. Chapter~\ref{chap:boogie} describes an encoding of the next state relations of imperative programs in FOOL. Chapter~\ref{chap:aws} describes an approach to network verification based on automated reasoning in first-order logic, which uses features of FOOL. Finally, Chapter~\ref{chap:tfx} describes TFX, the extension of the TPTP language that contains the syntax for FOOL.

Each of the papers contained in this thesis has been written and presented separately. As a result, the introductory remarks and preliminaries of some of the chapters necessarily overlap. Another consequence is that some ideas presented in earlier chapters are revisited and developed in later chapters. One example of such idea is the encoding of the next state relations of imperative programs in FOOL. A sketch of this encoding first appears in Chapter~\ref{chap:implementation} and preliminary experimental results are discussed in Chapter~\ref{chap:cnf}. The precise formal description of the encoding and extensive evaluation is however given later in Chapter~\ref{chap:boogie}. Another example is the set of syntactical constructs available in FOOL. The original description of FOOL in Chapter~\ref{chap:fool} does not include \LETIN\ expressions with simultaneous definitions, definitions of tuples and tuple expressions. These constructs are incuded in later chapters.

The contributions of the thesis are the cumulative contributions of all six papers. The rest of this chapter details the main contributions of each individual paper.

\subsection*{\hyperref[chap:fool]{Chapter 1.} A First Class Boolean Sort in\\First-Order Theorem Proving and TPTP}
The paper presents the syntax and semantics of \folb. We show that \folb\ is a modification of FOL and reasoning in it reduces to reasoning in FOL. We give a model-preserving \iffalse(modulo introduced definitions)\fi translation of \folb\ to FOL that can be used for proving theorems in \folb\ in a first-order prover. We discuss a modification of superposition calculus that can reason efficiently in the presence of boolean sort. This modification includes replacement of one of the boolean sort axioms with a specialised inference rule that we called \folb\ paramodulation. We note that the TPTP language can be changed to support \folb, which will also simplify some parts of the TPTP syntax. 

\paragraph{Statement of contribution.} The paper is co-authored with Laura Kov\'{a}cs and Andrei Voronkov. Evgenii Kotelnikov contributed to the formalisation of \folb{} and its translation to FOL.

\paragraph{Bibliographic information.} The paper has been published in the proceedings of the 8th Conference on Intelligent Computer Mathematics (CICM) in 2015~\cite{FOOL}.

\subsection*{\hyperref[chap:implementation]{Chapter 2.} The Vampire and the \folb{}}
The paper describes the implementation of \folb\ in Vampire. We extend and simplify the TPTP language by providing more powerful and uniform representations of \ITE\ and \LETIN\ expressions. We demonstrate usability and high performance of our implementation on two collections of benchmarks, coming from the higher-order part of the TPTP library and from the Isabelle interactive theorem prover. We compare the results of running Vampire on the benchmarks with those of SMT solvers and higher-order provers. Moreover, we compare the performance of Vampire with and without \folb{} paramodulation. We give a simple extension of \folb, allowing to express the next state relation of a program as a boolean formula which is linear in the size of the program.

\paragraph{Statement of contribution.} The paper is co-authored with Laura Kov\'{a}cs, Giles Reger and Andrei Voronkov. Evgenii Kotelnikov contributed with the implementation of \folb{} in Vampire and the experiments.

\paragraph{Bibliographic information.} The paper has been published in the proceedings of the 5th ACM SIGPLAN Conference on Certified Programs and Proofs (CPP) in 2016~\cite{VampireAndFOOL}.

\subsection*{\hyperref[chap:cnf]{Chapter 3.} A Clausal Normal Form Translation\\for \folb{}}
The paper presents a clausification algorithm that translates a FOOL formula to an equisatisfiable set of first-order clauses. This algorithm aims to minimise the number of clauses and the size of the resulting signature, especially on formulas with \ITE, \LETIN\ expressions and complex boolean structure. We demonstrate by experiments that the implementation of this algorithm in Vampire increases performance of the prover on \folb{} problems compared to the earlier translation of \folb{} formulas to full first-order logic.

\paragraph{Statement of contribution.} The paper is co-authored with Laura Kov\'{a}cs, Martin Suda and Andrei Voronkov. Evgenii Kotelnikov contributed with the extension of \newcnf{} that supports \folb{}, the implementation of this extension in Vampire and the experiments.

\paragraph{Bibliographic information.} The paper has been published in the proceedings of the 2nd Global Conference on Artificial Intelligence (GCAI) in 2016~\cite{FOOLCNF}.

\subsection*{\hyperref[chap:boogie]{Chapter 4.} A FOOLish Encoding of the Next State Relations of Imperative Programs}
The paper describes an encoding of the next state relations of imperative programs with variable updates and \ITE\ statements in FOOL. Based on this encoding the paper presents a translation of imperative programs annotated with their pre- and post-conditions to partial correctness properties of these programs. We demonstrate by experiments that this translation results in formulas that are easier for Vampire than the formulas produced by program verification tool such Boogie and BLT.

\paragraph{Statement of contribution.} The paper is co-authored with Laura Kov\'{a}cs and Andrei Voronkov. Evgenii Kotelnikov contributed with the formalised translation of imperative programs to FOOL and the experiments.

\paragraph{Bibliographic information.} The paper has been published in the proceedings of the 9th International Joint Conference on Automated Reasoning (IJCAR) in 2018~\cite{KKV18}.

\subsection*{\hyperref[chap:aws]{Chapter 5.} Checking Network Reachability Properties by Automated Reasoning in First-Order Logic}
The paper describes an approach for static verification of virtual private cloud networks using automated theorem proving for first-order logic. We model networks with Horn clauses and check first-order properties of these models using the Vampire theorem prover. We used Vampire both as a saturation-based theorem prover and a finite model builder for different kinds of checked properties.

\paragraph{Statement of contribution.} The chapter is co-authored with Pavle Suboti\'{c} and based on a joint work with Byron~Cook, Temesghen Kahsai and Sean~McLaughlin. Evgenii Kotelnikov contributed with the encoding of network rechability properties in first-order logic and the implementation of a checker for these problems based on Vampire.

\subsection*{\hyperref[chap:tfx]{Chapter 6.} TFX: The TPTP Extended Typed First-Order Form}
The paper presents the new language TFX that extends and simplifies the language of typed first-order formulas TFF. TFX includes the first class boolean sort, \ITE\ expressions, \LETIN\ expressions and tuples. The inclusion of these syntactic constructs was motivated by the work on FOOL and FOOL formulas can be directly expressed in TFX. TFX has been included in the latest release of the TPTP library.

\paragraph{Statement of contribution.} The paper is co-authored with Geoff Sutcliffe. Evgenii Kotelnikov contributed with the discussion of the TFX syntax, the description of FOOL and examples of FOOL problems.

\paragraph{Bibliographic information.} The paper has been published in the proceedings of the 6th Workshop on Practical Aspects of Automated Reasoning (PAAR) in 2018~\cite{SutcliffeK18}.

\section*{Related Work}
\addcontentsline{toc}{section}{Related Work}

\EK{

The equality can be finitely axiomatised in first-order logic as a congruence relation. However, resolution with equality axioms is known to generate enormous search spaces and thus is very inefficient. Rather than axiomatizing equality, first-order provers consider it part of the logic and implement specialized inference rules for equality reasoning. These inference rules include refinements of the paramodulation rule~\cite{WRCS67,Robinson1969}.

Treatment of sorts in FOL. Many-sorted resolution \cite{DBLP:conf/ijcai/Walther83}.

Extensionality resolution. In a more recent result~\cite{ATVA14}, Vampire was extended to support the extensionality resolution rule to efficiently reason with the extensionality axiom.

Linear integer arithmetic --- incomplete axiomatization, evaluation inference rule. Many problems, tackled by theorem provers, are written in the combination of first-order logic with theories, such as the theory of linear integer arithmetic. Theorem provers handle theories by automatically adding (possibly incomplete) theory axioms to the search space whenever an interpreted sort, function, or predicate is found in the input.

Algebraic datatypes. \cite{BPR18}

Higher-order logic in Vampire.

\folb{} contains features of higher-order logic. Some problems that previously required higher-order logic can now be expressed directly in \folb{}. For example, the current version of the TPTP library contains over a hundred of such problems. One can check these problems with first-order provers that support \folb{} rather than higher-order provers.

Finally, it is interesting to note that our \nfcnf{} algorithm naturally translates a quantified boolean formula (QBF), as realised in the FOOL language, into a CNF in effectively propositional logic (EPR). Specifically, every literal in this translation is a skolem predicate applied to boolean variables and constants $\true$ and $\false$. Obtaining a formula in EPR is a desirable property to have since there are first-order proving methods known to be efficient for dealing with the fragment (see e.g.~\cite{DBLP:conf/birthday/Korovin13}).

This example makes one think about representing sentences in various epistemic or first-order modal logics in FOOL.

}

