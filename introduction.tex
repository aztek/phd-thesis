% !TEX root = main.tex

This thesis studies automated theorem proving in first-order logic and its applications. The history of automated theorem proving in first-order logic dates back to the early 1950s (see e.g. \cite{bundy1999survey,davis2001early,harrison2007short} for a historical overview). Over the years proof search algorithms and implementations of automated theorem provers have matured and are now used for practical applications. Among these applications are static analysis and verification of software and hardware, automation for proof assistants, knowledge representation, natural language processing and others.

The efficient usage of first-order theorem provers might be challenging. One of the challenges is representation of application problems in first-order logic in a way that is efficient for automated reasoning. Systems that rely on first-order provers, such as program verification tools and proof assistants, usually do not deal with first-order logic natively. Instead, they translate problems in their respective domains (program properties or formulas in the logic of the proof assistant) to problems in first-order logic. There could be multiple ways of translating a problem because of the mismatch between the semantics of the domain and that of first-order logic. A theorem prover might succeed on the results of some of these translations and fail on the others. Users of a theorem prover might find designing a translation that is friendly to the prover to be a difficult task. Such translation might require solid knowledge of how theorem provers work and are implemented, something that the users of the prover might not have. Assessing whether a translation of a certain problem to first-order logic is good might be difficult as well. Such assessment can often only be made through tedious experiments with running theorem provers, configured with different settings, on the results of the translation. A perfect translation might not necessarily exist, because different translation might work better in different scenarios. Furthermore, for some types of problems, their translations to first-order logic cannot be efficiently handled by a theorem prover at all unless the prover is extended with specialised inference rules and heuristics.

The complexity of preparing problems for first-order theorem provers can be battled by extending the logic supported by the provers. Such extension should include theories and new syntactical features that are common in problems from application domains but sensitive to translations. The appropriate translation of these features to plain first-order logic therefore becomes the responsibility of the provers themselves. The right choice of new features and their efficient implementation in theorem provers facilitates applications of automated theorem proving. Firstly, users of theorem provers are relieved from the tedious translations and can express their problems closer to their original domains. Secondly, theorem provers are able to implement translations of these features that suit them best. Thirdly, theorem provers can try multiple different translations in the same proof attempt. Finally, theorem provers can enhance proof search for problems with specific features by implementing dedicated inference rules and preprocessing steps for these features.

This thesis addresses the following research question: \emph{which new extensions of first-order theorem provers are useful for applications and how can these extensions be efficiently implemented?} The thesis identifies that first class boolean sort, \ITE\ and \LETIN\ expressions are useful for problems from program verification and automation of proof assistants and are generally not supported by first-order theorem provers. The thesis presents a modification of first-order logic named FOOL that contains these features and gives new techniques for reasoning in it and using it. The thesis describes implementation details and challenges in the Vampire theorem prover, however the described extensions and their implementation can be carried out in any other first-order prover.

This chapter describes the background of the thesis and is structured as follows. First, we overview the key concepts of automated theorem proving in first-order logic. Then, we explain how program verification tools and proof assistants benefit from extensions of theorem provers presented in the thesis. Finally, we detail the main contributions of the thesis and overview its structure.

% how to construct proofs automatically using a computer. The latter is the domain of automated theorem proving. It is one of the central and hardest areas of computer mathematics and artificial intelligence. Automated methods of proving theorems precede the existence of computers.

% Algorithms of automated theorem proving are implemented in computer programs called theorem provers. A theorem prover takes a logical conjecture as input and tries to either construct its proof or demonstrate that the conjecture is invalid. Theorem provers can be classified by the logic they support. Propositional, first-order and higher-order logic are among the logics that received the most attention in automated theorem proving.

%Theorem provers work by applying \emph{inference rules}. An inference rule is a $n$-ary ($n>0$) relation on clauses written as \[\infer[,]{B}{A_1 & \ldots & A_n}\] where $A_1,\ldots,A_n$ are premises and $B$ is the conclusion. An \emph{inference system} $\mathcal{I}$ is a collection of inference rules.

\section*{Automated Theorem Proving in First-Order Logic}
\addcontentsline{toc}{section}{Automated Theorem Proving in First-Order Logic}

First-order logic is not decidable, there is no algorithm that could in general determine whether a given first-order formula is valid or not. First-order logic is semi-decidable, an algorithm that enumerates all finite derivations in the logical system until a given first-order formula is found, terminates if the formula is valid, and may run forever otherwise. If a formula is satisfiable but not valid, there is no algorithm that could in general demonstrate that. A well studied and generally best performing class of algorithms that search for validity of first-order problems are those based on \emph{saturation} and the calculus of \emph{resolution} and \emph{superposition}. These algorithms are implemented in automated theorem provers such as E~\cite{E13}, iProver~\cite{iProver} and Vampire~\cite{Vampire13}.

First-order theorem provers work with first-order formulas represented as sets of \emph{clauses}. A first-order formula is in a clausal normal form (CNF) if it is a universally quantified conjunction of disjunctions of literals. An alternative representation of a CNF is as a set of first-order clauses, where each clause is a finite multiset of literals. A \emph{clausification} algorithm converts an arbitrary first-order formula to a set of first-order clauses, preserving satisfiability. First-order provers that support formulas in full first-order logic implement such algorithms as part of their preprocessing of the input.

First-order theorem provers construct proofs by \emph{refutation}. Given a first-order problem of the form $\mathit{Premises}\implies\mathit{Conjecture}$, a theorem prover first negates the conjecture, obtaining $\mathit{Premises}\wedge\neg\mathit{Conjecture}$, then converts this formula to a set of clauses $S$ and attempts to show that $S$ is unsatisfiable by deriving contradiction (the empty clause). To that end, the theorem prover \emph{saturates} the set $S$ with respect to some \emph{inference system} $\mathcal{I}$ which is a collection of \emph{inference rules}. An inference rule is a $n$-ary ($n\ge0$) relation on clauses written as \[\infer[,]{B}{A_1 & \ldots & A_{n-1}}\] where $A_1,\ldots,A_{n-1}$ are premises and $B$ is the conclusion. A set of clauses is called saturated with respect to $\mathcal{I}$ if for every inference of $\mathcal{I}$ with premises in this set, the conclusion of the inference also belongs to that set. To saturate the set $S$, the theorem prover systematically and exhaustively applies inference rules from $\mathcal{I}$ to premises from $S$ and adds the conclusion of each inference to $S$. If the empty clause is derived during this process, then the initial set $S$ is unsatisfiable and the input problem is valid. In such case the theorem prover returns the proof of the problem as a tree of inferences with clauses from the initial set $S$ as leafs and the empty clause as the root. If after applying all inferences between clauses in the saturated set $S$ the empty clause has not been derived and the inference system $\mathcal{I}$ is complete then the initial set $S$ is satisfiable and the problem is not valid. In such case the theorem prover returns the saturated set $S$. Saturation might not terminate on a satisfiable set of clauses, in such case the theorem prover sooner or later runs out of resources and fails. In practice, finite saturation is rare and theorem provers focus on deriving the empty clause by implementing various techniques and heuristics that make exploration of the search space of clauses more efficient.

Modern theorem provers employ inference systems that include refinements of the calculus of resolution, derived from the work of Robinson~\cite{Robinson65}, and superposition, derived from the work of Bachmair and Ganzinger~\cite{BG94} (see also \cite{Ganzinger01,NieuwenhuisRubio:HandbookAR:paramodulation:2001}). The inference rules in this calculus are guarded with side conditions which determine whether a rule can be applied. These conditions prevent the search space of clauses from growing too fast and are essential in practice. The key concepts used in these conditions are a \emph{simplification ordering} and a \emph{literal selection function}. They are understood as parameters of the calculus. A simplification ordering on terms $\succ$ captures the notion of simplicity (see e.g. \cite{DBLP:books/el/RV01/DershowitzP01}) i.e. $t_1 \succ t_2$ implies that $t_2$ is in some way simpler than $t_1$. There are direct extensions of simplification ordering to literals and clauses. A literal selection function determines for a given clause which literals should be used for inferences. Figure~\ref{fig:intro/calculus} shows the most important inference rules of the superposition and resolution calculus (selected literals are underlined). In this figure, $\mathrm{mgu}$ denotes a most general unifier of two first-order terms and $L[s]$ ($t[s]$) denotes that a term $s$ occurs in a literal $L$ (term $t$).

% An example of such ordering, used in some theorem provers, is Knuth-Bendix ordering~\cite{KB83}.

% \paragraph{Saturation-based proof search.}
  % \EK{TODO

% attempts to saturate this set with respect to some inference system $\mathcal{I}$. The clause set is saturated if for every inference from $I$ with premises in $S$ the conclusion of the inference is also added to $S$.

% Even for small problems this search space can grow quickly and provers often employ heuristics to control its exploration.

% Robinsons's resolution calculus and many of its refinements are refutationally complete, meaning that a contradiction can be deduced from any unsatisfiable set of clauses.

% }

\begin{figure}[ht]
  \begin{equation*}
    \begin{aligned}
      &
      \begin{aligned}
        &
        \begin{aligned}
          \begin{aligned}
            &\text{\textbf{Resolution}}\\
            &\infer[,]{(C_1\vee C_2)\theta}{\underline{A} \vee C_1 & \underline{\neg A'} \vee C_2}
          \end{aligned}
          &\quad\quad
          \begin{aligned}
            &\text{\textbf{Factoring}}\\
            &\infer[,]{(A \vee C)\theta}{\underline{A} \vee A' \vee C}
          \end{aligned}
        \end{aligned}
        \\[0.25em]
        &\text{where, for both inferences, $\theta=\mathrm{mgu}(A,A')$ and $A$ is not an equality}
      \end{aligned}
      \\[1em]
      &
      \begin{aligned}
        &\text{\textbf{Superposition}}
        \\
        &
        \infer[, \begin{array}{l}\text{where $\theta=\mathrm{mgu}(l,s)$, $t\theta\not\succeq s\theta$}\\\text{and $L[r]$ is not an equality}\end{array}]{(L[r] \vee C_1 \vee C_2)\theta}{\underline{l \eql r} \vee C_1 & \underline{L[s]} \vee C_2}
        \\[0.5em]
        &
        \quad\quad\text{or}
        \\[0.4em]
        &
        \infer[, \begin{array}{l}\text{where $\theta=\mathrm{mgu}(l,s)$, $t\theta\not\succeq s\theta$, $t'\theta\not\succeq t[s]\theta$}\\\text{and $\otimes$ is either $\eql$ or $\not\eql$}\end{array}]{(t[r] \otimes t' \vee C_1 \vee C_2)\theta}{\underline{l \eql r} \vee C_1 & \underline{t[s] \otimes t'} \vee C_2}
      \end{aligned}
      \\[1em]
      &
      \begin{aligned}
        \begin{aligned}
          &\text{\textbf{Equality resolution}}\\
          &\infer[,]{C\theta}{\underline{s\eql t} \vee C}\\
          &\text{where $\theta=\mathrm{mgu}(s,t)$}
        \end{aligned}
        &\quad\quad
        \begin{aligned}
          &\text{\textbf{Equality factoring}}\\
          &\infer[,]{(t \not\eql t' \vee s' \eql t' \vee C)\theta}{\underline{s \eql t} \vee s' \eql t' \vee C}\\
          &\text{where $\theta=\mathrm{mgu}(s,t)$, $t\theta\not\succeq s\theta$ and $t'\theta\not\succeq s'\theta$}
        \end{aligned}
      \end{aligned}
    \end{aligned}
  \end{equation*}
  \caption{The inference rules of the superposition and resolution calculus.\label{fig:intro/calculus}}
\end{figure}

An important concept related to saturation in \emph{redundancy elimination}. A clause $C$ from a set $S$ is called redundant in $S$ if it is a logical consequence of clauses in $S$ strictly smaller than $C$ w.r.t. to a simplification ordering. Redundant clauses can be eliminated from the search space without compromising completeness. A powerful criterion of redundancy of a clause is \emph{subsumption}. A clause $A$ subsumes $B$ if some subclause of $B$ is an instance of $A$. If a clause $A$ from a set $S$ subsumes $B$, $B$ is redundant in $S$. \emph{Saturation up to redundancy}~\cite{NieuwenhuisRubio:HandbookAR:paramodulation:2001} terminates when the inference system cannot derive any new clauses that are not redundant in the search space. %The notion of redundancy improves the performance of theorem provers by constraining the growth of the search space.

Another powerful technique is \emph{splitting}~\cite{DBLP:conf/cade/HoderV13} of long clauses into smaller ones with disjoint sets of used variables so that the search space can be explored in smaller parts. This technique is motivated by the observation that long clauses slow down saturation based proof search. A recent improvement of splitting is the AVATAR architecture~\cite{DBLP:conf/cav/Voronkov14} that employs a SAT or SMT solver to guide splitting decisions.

%Another useful tool in reducing search space explosion is splitting [8] where clauses are split so that the search space can be explored in smaller parts.

% A new, highly successful, approach to splitting is found in the AVATAR architecture [23], which uses a Splitting module with a SAT solver at its core to make splitting decisions.

The aforementioned notions and methods and many other refinements of proof search, implemented in theorem provers, aim to constrain the growth of the search space and avoid unnecessary inferences. Ultimately, the behaviour of a theorem prover can be tuned in many different ways. Whether or not a theorem prover solves the input problem depends to a large degree on the choice of parameters of the proof search algorithm. Different combinations of these parameters can solve different problems. For that reason theorem provers such as E, iProver and Vampire implement \emph{portfolios} of proof search strategies. Based on certain characteristics of the input, theorem provers select the appropriate strategies and schedules for them, and then run these strategies one by one in a time-slicing fashion. Some of these strategies are designed to be refutationally incomplete~--- they cannot derive the empty clause from an arbitrary unsatisfiable set of clauses, but for some unsatisfiable sets of clauses they derive the empty clause very quickly. The usage of multiple proof search strategies in the same proof attempt allows theorem provers to succeed on a larger number of problems. Some provers also extend their portfolios with proof search techniques other than saturation. For example, Vampire includes in its portfolios an implementation of the Inst-Gen calculus~\cite{DBLP:conf/birthday/Korovin13} and a finite model builder~\cite{VampireFMB}.

Another contributing factor to the success of a theorem prover is how well the input problem is prepared to be processed by saturation. First-order theorem provers are known to be fragile with respect to the input. Multiple, often subtle, characteristics of a first-order problem might affect the performance of saturation based proof search. These characteristics include, for example, the number of clauses in the problem, the size of clauses and the size of the signature. Theorem provers implement elaborate preprocessing techniques, in particular improvements of clausification algorithms (see e.g. \cite{nonnengart2001computing,azmy2013computing,newcnf_fol}), that aim to produce good sets of clauses.

Some first-order formulas can be problematic for efficient proof search. A common technique employed by theorem provers is to replace such formulas with specialised inference rules. A well known example of this technique is handling of equality. Equality can be finitely axiomatised in first-order logic as a congruence relation. However, resolution and factoring with equality axioms are known to generate a lot of (mostly unnecessary) new clauses and thus is very inefficient. Rather than axiomatising equality, first-order provers consider it part of the logic and implement specialised inference rules for equality reasoning. These inference rules include refinements of the paramodulation rule~\cite{WRCS67,Robinson1969}. They are part of the standard arsenal of inference rules used by theorem provers. Another example is the extensionality resolution rule, implemented in Vampire~\cite{ATVA14}. This rule replaces difficult extensionality axioms that are routinely used in encodings of data collections and sets.

The performance of first-order theorem provers is evaluated empirically on large corpora of problems. Comparison of provers is mostly based on success rates and run times. The main corpus is the Thousands of Problems for Theorem Provers (TPTP) library~\cite{TPTP}. The problems in this corpus are written in a variety of languages, such as FOF for untyped first-order formulas, TFF0~\cite{tff0} for typed monomorphic first-order formulas and TFF1~\cite{tff1} for typed rank-1 polymorphic first-order formulas. The TPTP library is used as a basis for the annual CASC system competition~\cite{CASC}.

Many practical problems tackled by theorem provers are expressed in the combination of first-order logic and theories. For example, problems coming from program verification routinely use integer arithmetic, arrays and datatypes. Most interesting theories do not have a complete encoding in first-order logic and require dedicated support in theorem provers. Vampire handles the theory of integer arithmetic by (i) automatically adding incomplete relevant theory axioms to the search space; (ii) applying dedicated inference rules for ground evaluation of theory terms; and (iii) using AVATAR modulo theories~\cite{DBLP:conf/gcai/RegerB0V16}. Vampire supports the polymorphic theory or arrays by automatically instantiating theory axioms for each sort of arrays~\cite{VampireAndFOOL}. Finally, Vampire supports datatypes and co\-data\-types~\cite{BPR18}. Their underlying theory of term algebras cannot be finitely axiomatised in first-order logic, however complete reasoning with this theory was implemented using dedicated inference rules.

\section*{Extensions of First-Order Logic for Applications}
\addcontentsline{toc}{section}{Extensions of First-Order Logic for Applications}

%The two main areas of application of first-order theorem provers, considered in this thesis, are deductive program verification and automation of proof assistants. 

\paragraph{Deductive Program Verification.}
The task of a program verification tool is to check whether a given program satisfies its specification. A program specification can be expressed with logical formulas that annotate program statements and capture their properties. Typical examples of such properties are pre-conditions, post-conditions and loop invariants. These program properties are checked using various tools (see e.g. \cite{Bonacina10} for a detailed overview). Deductive program verification sees compliance with specification as a logical problem that can be checked by automated theorem provers. For that, program statements are first translated to logical formulas that capture the semantics of the statements. Then, a theorem is built with the translated formulas as premises and program properties as the conjecture. Validity of the theorem is interpreted as that the program statements have their annotated properties. Conversely, failure to show validity might indicate a bug in the program. Program verification frameworks such as Boogie~\cite{DBLP:conf/fmco/BarnettCDJL05}, Why3~\cite{DBLP:conf/esop/FilliatreP13} and Frama-C~\cite{FramaC} rely on automated theorem provers for checking program properties.

Theorem provers can be used not just for checking program properties, but also for generating them. Recent approaches in interpolation and loop invariant generation~\cite{McMillan08,fase2009,hoder2012popl} present initial results of using first-order theorem provers for generating quantified program properties. First-order theorem provers can also be used to generate program properties with quantifier alternations~\cite{fase2009}; such properties could not be generated fully automatically by any previously known method.

\paragraph{Automation of Proof Assistants.}
Proof assistants are software tools that assist users in constructing proofs of mathematical problems. Proof assistants use formalisations of mathematics based on higher-order logic (Isabelle/HOL~\cite{Isabelle}), type theory (Coq~\cite{Coq}), set theory (Mizar~\cite{Mizar}) and others. Many proof assistants enhance the workflow of their users by automatically filling in parts of the user's proof with the help of tactics. Tactics are specialised scripts that run a predefined collection of proof searching strategies. These strategies can be implemented inside the proof assistant itself or rely on third-party automated theorem provers~\cite{Sledgehammer,DBLP:conf/icms/UrbanHV10}. Automation using external theorem provers, including first-order ones, is implemented e.g. in the Sledgehammer extension~\cite{Sledgehammer} of Isabelle. Sledgehammer heuristically picks lemmas and definitions that might be necessary for the proof, translates them to the logic of automated theorem provers and hands over the resulting formulas to the provers. If one of the provers returns a proof, Sledgehammer uses this proof to reconstruct a proof in the calculus of Isabelle. The translation of Isabelle's lemmas and definitions might be incomplete because the logic of Isabelle is more expressive than that of automated provers.

The translation of the following features of programming languages and more expressive logics to plain first-order logic might be cumbersome and inefficient. This thesis presents features of FOOL that can be used for a more straightforward translation. Further, the thesis present methods of efficient support of these features and an implementation of these methods in Vampire.
\begin{enumerate}
  \item Boolean values in programming languages are used both as expressions in conditional and loop statements and as boolean flags passed as arguments to functions. A natural way of translating program statements with booleans into formulas is by translating conditions as formulas and function arguments as terms. Yet one cannot mix boolean terms and formulas in the same way in plain first-order logic. FOOL contains the boolean sort as its first class sort. Formulas in FOOL are indistinguishable from boolean terms which coincides with the treatment of booleans in programming languages.
  \item Properties expressed in higher-order logic routinely use quantification over the interpreted boolean sort; this is not allowed in plain first-order logic. FOOL allows quantification over the first class boolean sort. Besides proof assistants, the first class boolean sort is useful to higher-order automated theorem provers such as Satallax~\cite{Satallax} and Leo-II~\cite{LeoII} that employ first-order provers for their proof search.
  \item Imperative programs are structured as sequences of variable updates. Standard techniques for translating such sequences to logic involve computing a static single assignment (SSA) form of the program. Computation of an SSA form introduces intermediate variables and their presence in the resulting formula can deteriorate the performance of a theorem prover. FOOL contains \LETIN\ expressions. One can concisely express sequences of variable assignments in FOOL as nested \LETIN\ and leave the decision of naming intermediate states of the program or not to the theorem prover.
  \item Both programming language and logics of proof assistants routinely use conditional expressions and local definitions of functions. The standard approaches for translating them are inlining and naming. Either one of these approaches can result in difficult first-order formulas. FOOL contains \ITE\ expressions and allows \LETIN\ expressions to define function and predicate symbols with arbitrary arity. The choice between inlining and naming is left to the theorem prover itself which is better equipped to make it.
\end{enumerate}

\section*{Contributions of the Thesis}
\label{sect:intro:contributions}
\addcontentsline{toc}{section}{Contributions of the Thesis}
%This thesis contributes to the area of automated reasoning by exploring which extensions of first-order theorem provers facilitate their practical applications, in particular program verification and automation for proof assistants. This section summarises the main contributions of the thesis.

In summary, the work presented in this thesis
\begin{enumerate}
  \item introduces the extension FOOL of first-order logic that contains useful syntactical constructs that are usually not supported by first-order provers, mentioned before;
  \item explores how reasoning in FOOL can be efficiently implemented in existing automated theorem provers for first-order logic;
  \item gives practical evidence of usefulness of FOOL for application through examples and developed translation techniques;
  \item gives practical evidence of efficiency of reasoning with FOOL through experimental results on large diverse collections of problems.
\end{enumerate}

\paragraph{FOOL.}
The thesis presents FOOL, standing for first-order logic (FOL) with boolean sort. \folb{} extends ordinary many-sorted FOL with \begin{enumerate*}[label=(\roman*)]\item first class boolean sort, \item boolean variables used as formulas, \item formulas used as arguments to function and predicate symbols, \item \ITE\ expressions and \item \LETIN\ expressions.\end{enumerate*} \ITE\ and \LETIN\ expressions can occur as both terms and formulas. \LETIN\ expressions can use (multiple simultaneous) definitions of function symbols, predicate symbols, and tuples. The thesis presents the definition of FOOL, its semantics, and a simple model-preserving translation from \folb{} formulas to formulas of first-order logic. This translation can be used to support \folb{} in existing first-order provers.

\paragraph{Reasoning with FOOL.}
The thesis presents two approaches to an implementation of FOOL in first-order provers that improve over the simple translation of FOOL to FOL. The first approach is a new technique of dealing with the boolean sort in superposition theorem provers. This technique includes replacement of one of the boolean sort axioms with a specialised inference rule called FOOL paramodulation. The second approach is a new algorithm \nfcnf{} that transforms FOOL formulas directly to first-order clauses. The thesis presents an implementation of the simple translation from FOOL to FOL and both improved approaches in Vampire.

\paragraph{Applications of FOOL.}
The thesis presents an encoding of the next state relations of imperative programs in FOOL. Compared to similar methods, this encoding avoids introducing intermediate variables and results in FOOL formulas that concisely represent the structure of program fragments in logic.
%The thesis presents a translation of imperative programs annotated with their pre- and post-conditions to partial correctness properties of these programs.
The thesis presents a work on verification of virtual private cloud network configurations with Vampire. The encoding of verification problems in this work relies on first class booleans, the theory of arrays and the theory of tuples.

\paragraph{Practical Evaluation.}
The thesis presents extensive experiments on running Vampire, other first-order theorem provers, higher-order theorem provers and SMT solvers on FOL and FOOL problems. These problems come from various sources: benchmarks from the TPTP and SMT-LIB library, proof obligations generated by the Isabelle proof assistant, and verification conditions generated by multiple different program verification tools. The experimental results obtained with these problems show in particular that \begin{enumerate}
  \item Vampire with FOOL paramodulation performs better than Vampire with the simple translation from FOOL to FOL;
  \item Vampire with \nfcnf{} performs better that Vampire with FOOL paramodulation;
  \item Vampire performs better on verification conditions translated to FOOL than the same verification conditions translated to FOL using methods implemented in state-of-the-art verification tools.
\end{enumerate}

\paragraph{Impact on TPTP.}
The language of FOOL is a superset of TFF0~--- the monomorphic first-order part of the TPTP language. The thesis describes a modification of the TPTP language needed to represent \folb{} formulas. This modification has been included in the TPTP standard as the TPTP Extended Typed First-Order Form (TFX).

\paragraph{Impact on Vampire.}
The language of FOOL is a superset of the core theory of the SMT-LIB language~\cite{SMT-LIB}, the standard language of SMT solvers. First-order provers that support \folb{} can therefore reason about some problems from the SMT-LIB library. This opens up an opportunity to evaluate first-order provers on problems that were previously only checked by SMT solvers. Vampire gained support for SMT-LIB based on its implementation of FOOL, and since 2016 has been participating in the SMT-COMP competition~\cite{DBLP:conf/cav/BarrettMS05} where it contends against SMT solvers.

The support of both FOOL and theories such as arithmetic, arrays and datatypes, makes Vampire a convenient and powerful tool for reasoning about properties of programs.


\section*{Structure of the Thesis}
\label{sect:intro:overview}
\addcontentsline{toc}{section}{Structure of the Thesis}

The work described in this thesis has been carried out in six papers, each contained in a separate chapter. Four papers (Chapters~\ref{chap:fool}, \ref{chap:implementation}, \ref{chap:cnf} and \ref{chap:boogie}) were published in peer-reviewed conferences, one (Chapter~\ref{chap:tfx}) was published in a peer-reviewed workshop, and one (Chapter~\ref{chap:aws}) is a technical report not yet submitted for publication. The references of the papers have been combined into a single bibliography at the end of the thesis. Other than that, the papers have only been edited for formatting purposes, and in general appear in their original form.

The chapters of this thesis are arranged in the order in which their correspondent papers were written. Chapter~\ref{chap:fool} presents the syntax and semantics of FOOL. Chapter~\ref{chap:implementation} presents the implementation of FOOL in Vampire. Chapter~\ref{chap:cnf} presents an efficient clausification algorithm for FOOL. Chapter~\ref{chap:boogie} describes an encoding of the next state relations of imperative programs in FOOL. Chapter~\ref{chap:aws} describes an approach to network verification based on automated reasoning in first-order logic, which uses features of FOOL. Finally, Chapter~\ref{chap:tfx} describes TFX, the extension of the TPTP language that contains the syntax for FOOL.

Each of the papers contained in this thesis has been written and presented separately. As a result, the introductory remarks and preliminaries of some of the chapters overlap. Another consequence is that some ideas presented in earlier chapters are revisited and developed in later chapters. One example of such idea is the encoding of the next state relations of imperative programs in FOOL. A sketch of this encoding first appears in Chapter~\ref{chap:implementation} and preliminary experimental results are discussed in Chapter~\ref{chap:cnf}. The precise formal description of the encoding and extensive evaluation is however given later in Chapter~\ref{chap:boogie}. Another example is the set of syntactical constructs available in FOOL. The original description of FOOL in Chapter~\ref{chap:fool} does not include \LETIN\ expressions with simultaneous definitions, definitions of tuples and tuple expressions. These constructs are included in later chapters.

The contributions of the thesis are the cumulative contributions of all six papers. The rest of this section details the main contributions of each individual paper.

\subsection*{\hyperref[chap:fool]{Chapter 1.} A First Class Boolean Sort in\\First-Order Theorem Proving and TPTP}
The paper presents the syntax and semantics of \folb. We show that \folb\ is a modification of FOL and reasoning in it reduces to reasoning in FOL. We give a model-preserving \iffalse(modulo introduced definitions)\fi translation of \folb\ to FOL that can be used for proving theorems in \folb\ in a first-order prover. We discuss a modification of superposition calculus that can reason efficiently in the presence of boolean sort. This modification includes replacement of one of the boolean sort axioms with a specialised inference rule that we called \folb\ paramodulation. We note that the TPTP language can be changed to support \folb, which will also simplify some parts of the TPTP syntax. 

\paragraph{Statement of contribution.} The paper is co-authored with Laura Kov\'{a}cs and Andrei Voronkov. Evgenii Kotelnikov contributed to the formalisation of \folb{} and its translation to FOL.

\paragraph{Bibliographic information.} The paper has been published in the proceedings of the 8th Conference on Intelligent Computer Mathematics (CICM) in 2015~\cite{FOOL}.

\subsection*{\hyperref[chap:implementation]{Chapter 2.} The Vampire and the \folb{}}
The paper describes the implementation of \folb\ in Vampire. We extend and simplify the TPTP language by providing more powerful and uniform representations of \ITE\ and \LETIN\ expressions. We demonstrate usability and high performance of our implementation on two collections of benchmarks, coming from the higher-order part of the TPTP library and from the Isabelle interactive theorem prover. We compare the results of running Vampire on the benchmarks with those of SMT solvers and higher-order provers. Moreover, we compare the performance of Vampire with and without \folb{} paramodulation. We give a simple extension of \folb, allowing to express the next state relation of a program as a boolean formula which is linear in the size of the program.

\paragraph{Statement of contribution.} The paper is co-authored with Laura Kov\'{a}cs, Giles Reger and Andrei Voronkov. Evgenii Kotelnikov contributed with the implementation of \folb{} in Vampire and the experiments.

\paragraph{Bibliographic information.} The paper has been published in the proceedings of the 5th ACM SIGPLAN Conference on Certified Programs and Proofs (CPP) in 2016~\cite{VampireAndFOOL}.

\subsection*{\hyperref[chap:cnf]{Chapter 3.} A Clausal Normal Form Translation\\for \folb{}}
The paper presents a clausification algorithm that translates a FOOL formula to an equisatisfiable set of first-order clauses. This algorithm aims to minimise the number of clauses and the size of the resulting signature, especially on formulas with \ITE, \LETIN\ expressions and complex boolean structure. We demonstrate by experiments that the implementation of this algorithm in Vampire increases performance of the prover on \folb{} problems compared to the earlier translation of \folb{} formulas to full first-order logic. We extended Vampire with new preprocessing options that can be used to strengthen its portfolios.

\paragraph{Statement of contribution.} The paper is co-authored with Laura Kov\'{a}cs, Martin Suda and Andrei Voronkov. Evgenii Kotelnikov contributed with the extension of \newcnf{} that supports \folb{}, the implementation of this extension in Vampire and the experiments.

\paragraph{Bibliographic information.} The paper has been published in the proceedings of the 2nd Global Conference on Artificial Intelligence (GCAI) in 2016~\cite{FOOLCNF}.

\subsection*{\hyperref[chap:boogie]{Chapter 4.} A FOOLish Encoding of the Next State Relations of Imperative Programs}
The paper describes an encoding of the next state relations of imperative programs with variable updates and \ITE\ statements in FOOL. Based on this encoding the paper presents a translation of imperative programs annotated with their pre- and post-conditions to partial correctness properties of these programs. We demonstrate by experiments that this translation results in formulas that are easier for Vampire than the formulas produced by program verification tool such Boogie and BLT.

\paragraph{Statement of contribution.} The paper is co-authored with Laura Kov\'{a}cs and Andrei Voronkov. Evgenii Kotelnikov contributed with the formalisation of the translation of imperative programs to FOOL and the experiments.

\paragraph{Bibliographic information.} The paper has been published in the proceedings of the 9th International Joint Conference on Automated Reasoning (IJCAR) in 2018~\cite{KKV18}.

\subsection*{\hyperref[chap:aws]{Chapter 5.} Checking Network Reachability Properties by Automated Reasoning in First-Order Logic}
The paper describes an approach for static verification of virtual private cloud networks using automated theorem proving for first-order logic. We model networks with Horn clauses and check first-order properties of these models using the Vampire theorem prover. We used Vampire both as a saturation-based theorem prover and a finite model builder for different kinds of checked properties.

\paragraph{Statement of contribution.} The chapter is co-authored with Pavle Suboti\'{c} and based on a joint work with Byron~Cook, Temesghen Kahsai and Sean~McLaughlin. Evgenii Kotelnikov contributed with the encoding of network reachability properties in first-order logic and the implementation of a checker for these problems based on Vampire.

\subsection*{\hyperref[chap:tfx]{Chapter 6.} TFX: The TPTP Extended Typed First-Order Form}
The paper presents the new language TFX that extends and simplifies the language of typed first-order formulas TFF. TFX includes the first class boolean sort, \ITE\ expressions, \LETIN\ expressions and tuples. The inclusion of these syntactic constructs was motivated by the work on FOOL and FOOL formulas can be directly expressed in TFX. TFX has been included in the latest release of the TPTP library.

\paragraph{Statement of contribution.} The paper is co-authored with Geoff Sutcliffe. Evgenii Kotelnikov contributed with the discussion of the TFX syntax, the description of FOOL and examples of FOOL problems.

\paragraph{Bibliographic information.} The paper has been published in the proceedings of the 6th Workshop on Practical Aspects of Automated Reasoning (PAAR) in 2018~\cite{SutcliffeK18}.

%\section*{Conclusion}
%\addcontentsline{toc}{section}{Conclusion}
%FOOL can be used to express quantified boolean formulas (QBF) thanks to its first class boolean sort. The clausification algorithm \nfcnf{}, presented in Chapter~\ref{chap:cnf}, translates these formulas into a CNF in effectively propositional logic (EPR). Obtaining a formula in EPR is a desirable property to have since there are first-order proving methods known to be efficient for dealing with the fragment (see e.g.~\cite{DBLP:conf/birthday/Korovin13}).

%\EK{This example makes one think about representing sentences in various epistemic or first-order modal logics in FOOL.}

%The thesis focuses on practical features extending first-order theorem provers for making them better suited for applications of program verification and proof automation for interactive theorem provers.

% Furthermore, some problems that previously required higher-order logic can now be expressed directly in FOOL. For example, the current version of the TPTP library contains over a hundred of such problems. One can check these problems with first-order provers that support FOOL rather than higher-order provers.